---
layout: post
title: "Swift concurrency: Practical GCD, Part I"
description: "Swift concurrency series"
category: articles
tags: [iOS, OSX, Apple Swift, Grand Central Dispatch, Concurrency, Mobile Development]
comments: true
---

As mentioned in the previous part of the series, libdispatch aka the Grand Central Dispatch is at the core of concurrency operations for all Darwin platform. libdispatch is a low level C library that enables concurrent execution on multi-processor hardware and provides abstractions for writing concurrent code based on tasks and queues.

Despite being low level, GCD is surprisingly easy to use and is ubiquitous in all kinds of iOS / OSX applications. It makes it trivial to do things like spinning of a task on background thread and then calling back to the main UI thread with the results, while automatically taking care of the underlying complexities such as scheduling and priorities, CPU throughput, concurrency vs parallelism, etc. with appropriate values for individual platforms.

**The Basics**

In a nutshell, GCD introduces the concepts of thread-safe FIFO queues and enables submitting tasks. The queues could be either serial or concurrent, where serial queues are guaranteed to executed one task at a time in the order of the tasks' submission. Concurrent queues can execute multiple tasks at the same time, and while GCD grantees start order of the submitted task their rest of the execution details such as number of concurrently running tasks and their priorities are automatically decided by the system.

In Swift terms, a task is typically a closure and it can also be submitted to a GCD queue either synchronously or asynchronously.

With that knowledge, let's do already something:

{% highlight swift %}
let q = dispatch_get_global_queue(0,0)
dispatch_async(q) {
    print("hi from a separate thread")

    dispatch_async(dispatch_get_main_queue()) {
        print("all done, and now back to the main thread")
    }
}
{% endhighlight %}

The code above concurrently prints a message and then gets back to synchronously reports results on the main application thread.

Despite simplicity of the example, a number of things happen under the hood. After the code is submitted to one of the global concurrent queues, GCD takes care of prioritizing and scheduling its execution on one of the available CPUs, eventually spinning of a new thread or taking one from its thread pool and actually running the code.

**Let's get some more control**

With GCD taking care of all numerous platform-dependent settings around tasks scheduling & priorities, it also provides a clear and concise way for developers to express their intents.

Since iOS8, _Quality of Service_ gives developers several predefined priory levels that can be  assigned to various units of works. The priority levels can be used for queues, threads and tasks alike.

QOS breaks out things into four distinct categories:

 * _User Interactive_: work is done synchronously on the main thread, such as updating the UI

 * _User Initiated_: something that the user started, with expectation of prompt results, e.g. opening a document

 * _Utility_: work that may take a while and is not expected to be finished right away, such as uploading images while showing overall progress

 * _Background_: Not related to current activities, such as maintenance, indexing, backup, etc.

The QOS API is pretty neat, e.g. for our example basically all it takes is simply selecting the required QOS level that will then determine the appropriate system queue:

![queues]({% if site.baseurl %}{{ site.baseurl }}{% endif %}/images/QOS.png)

Code completion suggestions directly map to the to the four main QOS categories, with some additional values of _QOS_CLASS_DEFAULT_[^1], _QOS_CLASS_UNSPECIFIED_[^2], and _QOS_MIN_RELATIVE_PRIORITY_[^3].


Having mastered the QOS basics, lets evolve our code sample and run it via a playground:

{% highlight swift %}
import Foundation
import XCPlayground

XCPlaygroundPage.currentPage.needsIndefiniteExecution = true

let currentQueueLabel = {() -> String? in
    let queue_Label = dispatch_queue_get_label(DISPATCH_CURRENT_QUEUE_LABEL)
    return String(CString: queue_Label, encoding: NSUTF8StringEncoding)
}

let q = dispatch_get_global_queue(QOS_CLASS_UTILITY, 0)
dispatch_async(q) {
    if let label_name = currentQueueLabel() {
        print("Now on a GCD thread with QOS class: \(label_name)")
    }

    dispatch_async(dispatch_get_main_queue()) {
        if let label_name = currentQueueLabel() {
            print("And now back to: \(label_name)")
        }
        XCPlaygroundPage.currentPage.finishExecution()
    }
}
{% endhighlight %}
{% highlight bash %}
Now on a GCD thread with QOS class: com.apple.root.utility-qos
And now back to: com.apple.main-thread
{% endhighlight %}

===========
Optimizing further with GCD’s API is where things really get fun. If one is creating some work that has nothing to do with the flow of execution, for instance, the DISPATCH_BLOCK_DETACHED flag can be called to action:
dispatch_block_create(DISPATCH_BLOCK_DETACHED, {
    //Work
})
The benefit here is that GCD knows the work being done inside the block has nothing to do with the flow of execution. This cuts out some of the fluff, like assigning an activity ID, QoS propagation, and other properties of the execution context
===========

***Choosing Queue type***

Grand Central Dispatch provide the following types of queue:
* Serial Main Queue: This is a common choice to update the UI after completing work in a task on a concurrent queue. To do this, you’ll code one closure inside another. As well, if you’re in the main queue and call dispatch_async targeting the main queue, you can guarantee that this new task will execute sometime after the current method finishes.

Having mastered QOS basics, what kind of queue is


Finally, you can also create your own custom serial or concurrent queues. That means you have at least five queues at your disposal: the main queue, four global dispatch queues, plus any custom queues that you add to the mix!


Custom Serial Queue: A good choice when you want to perform background work serially and track it. This eliminates resource contention since you know only one task at a time is executing. Note that if you need the data from a method, you must inline another closure to retrieve it or consider using dispatch_sync.
Main Queue (Serial): This is a common choice to update the UI after completing work in a task on a concurrent queue. To do this, you’ll code one closure inside another. As well, if you’re in the main queue and call dispatch_async targeting the main queue, you can guarantee that this new task will execute sometime after the current method finishes.
Concurrent Queue: This is a common choice to perform non-UI work in the background.



when have a queue, can submit tasks

dispatch_sync
    adding to the queue, scheduler decides, then executes, you have to wait
dispatch_async


Dispatch queues let you execute arbitrary blocks of code either asynchronously or synchronously with respect to the caller. You can use dispatch queues to perform nearly all of the tasks that you used to perform on separate threads. The advantage of dispatch queues is that they are simpler to use and much more efficient at executing those tasks than the corresponding threaded code.

Serial queues (also known as private dispatch queues)


The main dispatch queue is a globally available serial queue that executes tasks on the application’s main thread. This queue works with the application’s run loop (if one is present) to interleave the execution of queued tasks with the execution of other event sources attached to the run loop. Because it runs on your application’s main thread, the main queue is often used as a key synchronization point for an application.


A dispatch group is a way to monitor a set of block objects for completion. (You can monitor the blocks synchronously or asynchronously depending on your needs.) Grou

* * *

[^1]: _QOS_CLASS_DEFAULT_ is simply a value used when no specific QOS info was provided, and is the default value for both queues and threads. Priority-wise, it sits between _User Interactive_ and _User Initiated_.

[^2]:_QOS_CLASS_UNSPECIFIED_ is tied to the concept of QOS propagation, where QoS is inferred  from the caller's QOS level. Such propagation simply transfers the QOS level, except for _User Interactive_ that is automatically translated to _User Initiated_.

[^3]:_QOS_MIN_RELATIVE_PRIORITY_ supports relative position within a QoS Class band. It is only within a given QOS class and intended for unusual situations such as e.g. interdependent work within same QOS class.
